{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import io\n",
        "from tqdm import tqdm\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "OuE1iLH3HBbo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}\n",
        "print(alphabets2index)\n",
        "index2alphabets = {i: alphabet for i, alphabet in enumerate(alphabets)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOlYI34rHHr1",
        "outputId": "073b78fd-aff9-41cc-8a37-47aabb5f1a31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '0': 52, '1': 53, '2': 54, '3': 55, '4': 56, '5': 57, '6': 58, '7': 59, '8': 60, '9': 61}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/'):\n",
        "    for filename in filenames[:3]:\n",
        "        print(os.path.join(dirname, filename))\n",
        "    if len(filenames) > 3:\n",
        "        print(\"...\")\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKy7T2ozINaj",
        "outputId": "186773a2-e889-4b36-cc20-7eb08604b6d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/captcha-hacker-2023-spring.zip\n",
            "/kaggle/dataset/sample_submission.csv\n",
            "/kaggle/dataset/test/task2/dreFISY5A8elpMKK.png\n",
            "/kaggle/dataset/test/task2/13Wfs6YbjJTVlClY.png\n",
            "/kaggle/dataset/test/task2/IN9vKdhs2RhWsDiw.png\n",
            "...\n",
            "/kaggle/dataset/test/task3/kLjULZiHIj8uWdHR.png\n",
            "/kaggle/dataset/test/task3/fWkcA63LEHbSrJIN.png\n",
            "/kaggle/dataset/test/task3/DBO0TS2J09rA8fdL.png\n",
            "...\n",
            "/kaggle/dataset/test/task1/gXb4I8nnMD8wp8Is.png\n",
            "/kaggle/dataset/test/task1/mr6b36cQdcoidaGh.png\n",
            "/kaggle/dataset/test/task1/pTKVsDqscDb50LQV.png\n",
            "...\n",
            "/kaggle/dataset/train/annotations.csv\n",
            "/kaggle/dataset/train/task2/xKdEhdwRMuTpYJN9.png\n",
            "/kaggle/dataset/train/task2/64tSL8zTFH8AN7L5.png\n",
            "/kaggle/dataset/train/task2/mc2JOVUgrIr7RQGo.png\n",
            "...\n",
            "/kaggle/dataset/train/task3/7MWp2K915drw2FLZ.png\n",
            "/kaggle/dataset/train/task3/RwV12vmr0J9xc3e9.png\n",
            "/kaggle/dataset/train/task3/G8focQMqdQ7MqP7Q.png\n",
            "...\n",
            "/kaggle/dataset/train/task1/t92un1ppRzA4u6bx.png\n",
            "/kaggle/dataset/train/task1/VIBOQUyPFDroWDwl.png\n",
            "/kaggle/dataset/train/task1/plVlZnknj2pxg1d9.png\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/kaggle/dataset/train\"\n",
        "TEST_PATH = \"/kaggle/dataset/test\"\n",
        "device = 'cuda'\n",
        "\n",
        "# try device = \"cuda\" \n",
        "# and change your settings/accelerator to GPU if you want it to run faster if your using kaggle's enviroment"
      ],
      "metadata": {
        "id": "-Pa_TPagISy8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_1= transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # 添加灰階轉換\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229]),  # 只有一個通道的均值和標準差\n",
        "])\n"
      ],
      "metadata": {
        "id": "u4UfV-5DHLbH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Task1Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
        "        # img = cv2.resize(img, (32, 32))\n",
        "        # img = np.mean(img, axis=2)\n",
        "        img = transform_1(img)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor(img ), filename\n",
        "        else:\n",
        "            return torch.FloatTensor(img ), alphabets2index[label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "vdQss6VTHNU3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18_1, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(512, 62)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.model(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "W6DbqdenHPjh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "model = ResNet18_1().to(device)\n",
        "PATH_1 = \"/content/drive/MyDrive/final_PR_weight/model_1.pt\"\n",
        "with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n",
        "    for row in csv.reader(csvfile, delimiter=','):\n",
        "        test_data.append(row)\n",
        "\n",
        "# !rm -f submission.csv\n",
        "if os.path.exists('submission.csv'):\n",
        "    file = open('submission.csv', 'w', newline='')\n",
        "    csv_writer = csv.writer(file)\n",
        "else:\n",
        "    file = open('submission.csv', 'w', newline='')\n",
        "    csv_writer = csv.writer(file)\n",
        "    csv_writer.writerow([\"filename\", \"label\"])\n",
        "\n",
        "test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=64, num_workers=4, drop_last=False, shuffle=False)\n",
        "\n",
        "model.load_state_dict(torch.load(PATH_1))\n",
        "\n",
        "print( len(test_data) )\n",
        "\n",
        "model.eval()\n",
        "cnt = 0\n",
        "for image, filenames in test_dl:\n",
        "    image = image.to(device)\n",
        "    \n",
        "    pred = model(image)\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    \n",
        "    for i in range(len(filenames)):\n",
        "      csv_writer.writerow([filenames[i], alphabets[pred[i].item()]])\n",
        "      cnt += 1\n",
        "print(cnt) # 6500\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LDp-QTeHUP1",
        "outputId": "bf4b4900-712a-4f61-cea6-2262ee74696b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10001\n",
            "6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_2= transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # 添加灰階轉換\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229]),  # 只有一個通道的均值和標準差\n",
        "])"
      ],
      "metadata": {
        "id": "ANcJm84SHZGE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Task2Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
        "        img = transform_2(img)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor( img ), filename\n",
        "        else:\n",
        "            char_label = np.zeros(124)\n",
        "            j = 0\n",
        "            for i in label :\n",
        "               char_label[alphabets2index[i]+j] = 1\n",
        "               j = j + 62\n",
        "            return torch.FloatTensor(img ), char_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "5lmye0COHbGx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18_2, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(512, 124)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.model(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "mMPTJoyAHc2G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if os.path.exists('submission.csv'):\n",
        "#     csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
        "# else:\n",
        "#     csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
        "#     csv_writer.writerow([\"filename\", \"label\"])\n",
        "\n",
        "test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=64, num_workers=4, drop_last=False, shuffle=False)\n",
        "\n",
        "model = ResNet18_2().to(device)\n",
        "PATH_2 = \"/content/drive/MyDrive/final_PR_weight/model_2.pt\"\n",
        "model.load_state_dict(torch.load(PATH_2))\n",
        "model.eval()\n",
        "for image, filenames in test_dl:\n",
        "    image = image.to(device)\n",
        "    pred = model(image)\n",
        "    pred = pred.data.cpu().numpy()\n",
        "    pred_chars = list()\n",
        "    for j in range(pred.shape[0]):\n",
        "      ans = \"\"\n",
        "      for k in range(2) :\n",
        "        max = -10000\n",
        "        index = 0\n",
        "        for i in range(62):\n",
        "          if pred[j][i+k*62] > max:\n",
        "            index=i\n",
        "            max=pred[j][i+k*62]\n",
        "        ans += alphabets[index]\n",
        "      pred_chars.append(ans)\n",
        "    for i in range(len(filenames)):\n",
        "        csv_writer.writerow([filenames[i], pred_chars[i]])\n",
        "        cnt += 1\n",
        "print(cnt) # 6500\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1sBar7hHfyj",
        "outputId": "4073423a-43c6-4b15-b321-9879686f9f25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_3= transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # 添加灰階轉換\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229]),  # 只有一個通道的均值和標準差\n",
        "])"
      ],
      "metadata": {
        "id": "lUDRJcwdHiGV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Task3Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
        "        # img = cv2.resize(img, (32, 32))\n",
        "        # img = np.mean(img, axis=2)\n",
        "        img = transform_3(img)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor(img) , filename\n",
        "        else:\n",
        "            char_label = np.zeros(248)\n",
        "            j = 0\n",
        "            for i in label :\n",
        "               char_label[alphabets2index[i]+j] = 1\n",
        "               j = j + 62\n",
        "            return torch.FloatTensor(img), char_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "9XQ1yXgiHju-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18_3, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(512, 248)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.model(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "o_vLsa0lHlv3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if os.path.exists('submission.csv'):\n",
        "#     csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
        "# else:\n",
        "#     csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
        "#     csv_writer.writerow([\"filename\", \"label\"])\n",
        "test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=64, num_workers=4, drop_last=False, shuffle=False)\n",
        "model = ResNet18_3().to(device)\n",
        "PATH_3 = \"/content/drive/MyDrive/final_PR_weight/model_3.pt\"\n",
        "model.load_state_dict(torch.load(PATH_3))\n",
        "\n",
        "model.eval()\n",
        "for image, filenames in test_dl:\n",
        "    image = image.to(device)\n",
        "    pred = model(image)\n",
        "    pred = pred.data.cpu().numpy()\n",
        "    pred_chars = list()\n",
        "    for j in range(pred.shape[0]):\n",
        "      ans = \"\"\n",
        "      for k in range(4) :\n",
        "        max = -10000\n",
        "        index = 0\n",
        "        for i in range(62):\n",
        "          if pred[j][i+k*62] > max:\n",
        "            index=i\n",
        "            max=pred[j][i+k*62]\n",
        "        ans += alphabets[index]\n",
        "      pred_chars.append(ans)\n",
        "    for i in range(len(filenames)):\n",
        "      csv_writer.writerow([filenames[i], pred_chars[i]])\n",
        "      cnt += 1\n",
        "\n",
        "\n",
        "print(cnt) # 6500\n",
        "\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1brX36IGHonE",
        "outputId": "ab38db64-51d1-4b56-8b91-9dca216519d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    }
  ]
}